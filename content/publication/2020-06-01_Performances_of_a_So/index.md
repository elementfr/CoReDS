+++
title = "Performances of a Solution to Semi-Automatically Fill eCRF with Data from the Electronic Health Record: Protocol for a Prospective Individual Participant Data Meta-Analysis."
date = "2020-06-01"
authors = ["Griffon Nicolas", "Pereira Helena", "Djadi-Prat Juliette", "Garcia Maria Teresa", "Testoni Sara", "Cariou Manon", "Hilbey Jacques", "N'Dja Aurele", "Navarro Gregory", "Gentili Nicola", "Nanni Oriana", "Raineri Massimo", "Chatellier Gilles", "Gomez De La Camara Agustin", "Lewi Martine", "Sundgren Mats", "Daniel Christel", "Garvey Almenia", "Todorovic Marija", "Ammour Nadir"]
publication_types = ["2"]
publication = "Studies in health technology and informatics, https://doi.org/10.3233/SHTI200184"
publication_short = "Studies in health technology and informatics, https://doi.org/10.3233/SHTI200184"
abstract = "Clinical trial data collection still relies on a manual entry from information available in the medical record. This process introduces delay and error risk. Automating data transfer from Electronic Health Record (EHR) to Electronic Data Capture (EDC) system, under investigators' supervision, would gracefully solve these issues. The present paper describes the design of the evaluation of a technology allowing EHR to act as eSource for clinical trials. As part of the EHR2EDC project, for 6 ongoing clinical trials, running at 3 hospitals, a parallel semi-automated data collection using such technology will be conducted focusing on a limited scope of data (demographic data, local laboratory results, concomitant medication and vital signs). The evaluation protocol consists in an individual participant data prospective meta-analysis comparing regular clinical trial data collection to the semi-automated one. The main outcome is the proportion of data correctly entered. Data quality and associated workload for hospital staff will be compared as secondary outcomes. Results should be available in 2020."
abstract_short = ""
image_preview = ""
selected = false
projects = []
tags = []
url_pdf = ""
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""
math = true
highlight = true
[header]
image = ""
caption = ""
+++
<a href="https://www.scimagojr.com/journalsearch.php?q=&amp;tip=sid&amp;exact=no" title="SCImago Journal &amp; Country Rank"><img border="0" src="https://www.scimagojr.com/journal_img.php?id=" alt="SCImago Journal &amp; Country Rank"  /></a>
**SCImago Journal Rank (SJR)** est un indicateur de notoriété des revues indexées à partir de 1996 dans la base de données Scopus de l’éditeur Elsevier. Le SJR a été créé par le groupe de travail SCImago Research Group (SRG) de l’Université de Grenade et Alcana de Henares en Espagne.  
  
Le SJR d’une revue est le nombre de fois où un article de cette revue est cité par d’autres articles pendant les 3 ans qui suivent sa publication, chaque citation reçue étant pondérée par la notoriété de la revue citante. Les articles « citants » sont issus d’autres revues et de la revue notée. Les citations d’articles de la revue par des articles de cette même revue (on parle d’autocitations) sont ainsi incluses dans le calcul du SJR, mais dans une limite de 35 %. Dans le calcul du SJR, le nombre de citations reçues par une revue est rapporté au nombre d’articles publiés par la revue au cours des 3 années qui précèdent.  
  
L'ensemble des revues a été classé en fonction de leur SJR et divisé en quatre groupes égaux, quartiles. Q1 (vert) comprend le quart des journaux avec les valeurs les plus élevées, Q2 (jaune) les deuxièmes valeurs les plus élevées, Q3 (orange) les troisièmes valeurs les plus élevées et Q4 (rouge) les valeurs les plus faibles.  
  
Différent entre le **SJR** et l'**Impact Factor** :  
- Le SJR est calculé pour une période de citation de 3 ans. Il tient compte de la notoriété des revues citantes. Il inclut de façon limitée les autocitations d’une revue ;  
- L'Impact Factor est calculé pour une période de citation de 2 ans. Il ne tient pas compte de la notoriété des revues citantes. Il inclut toutes les autocitations d’une revue.
